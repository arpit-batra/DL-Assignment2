{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, ReLU, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_to_visualize(layer):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(img_to_visualize)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "\n",
    "    n = convolutions.shape[0]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "\n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(len(convolutions)):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[i], cmap='gray')\n",
    "\n",
    "\n",
    "def print_different_scores(cm,file):\n",
    "\t# print(cm)\n",
    "\trecall=[]\n",
    "\tprecision=[]\n",
    "\trecall_val = 0\n",
    "\taccuracy=0\n",
    "\ttotal_sum=0\n",
    "\tfor i in range(len(cm)):\n",
    "\t\tnum = cm[i][i]\n",
    "\t\taccuracy+=num\n",
    "\t\trow_sum=cm[i].sum()\n",
    "\t\tcol_sum=cm[:,i].sum()\n",
    "\t\ttotal_sum+=row_sum\n",
    "\t\t# print ('row_sum= ', row_sum)\n",
    "\t\t# print ('col_sum= ', col_sum)\n",
    "\n",
    "\t\trecall_val = (1.0*num/row_sum);\n",
    "\t\trecall.append(recall_val);\n",
    "\t\tprecision_val = (1.0*cm[i][i]/cm[:,i].sum());\n",
    "\t\tprecision.append(precision_val);\n",
    "\n",
    "\taccuracy = (1.0*accuracy/total_sum)\n",
    "\tprint('accuracy = ',accuracy)\n",
    "\t# print ('recall = ',recall)\n",
    "\t# print ('precision = ',precision)\n",
    "\tf_score=[]\n",
    "\tfor i in range(len(recall)):\n",
    "\t\tval = 2.0 * recall[i] * precision[i]\n",
    "\t\tval /= (precision[i]+recall[i])\n",
    "\t\tf_score.append(val)\n",
    "\n",
    "\t# print ('f_score = ',f_score)\n",
    "\n",
    "\tf= open(file+\".txt\",\"w\")\n",
    "\tf.write('confusion_matrix\\n')\n",
    "\tfor i in range(len(cm)):\n",
    "\t\tfor j in range(len(cm[0])):\n",
    "\t\t\tif(j<len(cm[0])-1):\n",
    "\t\t\t\tf.write(str(cm[i][j])+' & ')\n",
    "\t\t\telse:\n",
    "\t\t\t\tf.write(str(cm[i][j])+\" \\\\\"+\"\\\\\")\n",
    "\t\tf.write('\\n')\n",
    "\t\t\n",
    "\tf.write('recall\\n')\n",
    "\tfor j in range(len(recall)):\n",
    "\t\tif(j<len(recall)-1):\n",
    "\t\t\tf.write(str(float(\"{0:.3f}\".format(recall[j])))+' & ')\n",
    "\t\telse:\n",
    "\t\t\tf.write(str(float(\"{0:.3f}\".format(recall[j])))+\" \\\\\"+\"\\\\\")\n",
    "\tf.write('\\n')\n",
    "\n",
    "\tf.write('precision\\n')\n",
    "\tfor j in range(len(precision)):\n",
    "\t\tif(j<len(precision)-1):\n",
    "\t\t\tf.write(str(float(\"{0:.3f}\".format(precision[j])))+' & ')\n",
    "\t\telse:\n",
    "\t\t\tf.write(str(float(\"{0:.3f}\".format(precision[j])))+\" \\\\\"+\"\\\\\")\n",
    "\tf.write('\\n')\n",
    "\t\n",
    "\tf.write('f_score\\n')\n",
    "\tfor j in range(len(f_score)):\n",
    "\t\tif(j<len(f_score)-1):\n",
    "\t\t\tf.write(str(float(\"{0:.3f}\".format(f_score[j])))+' & ')\n",
    "\t\telse:\n",
    "\t\t\tf.write(str(float(\"{0:.3f}\".format(f_score[j])))+\" \\\\\"+\"\\\\\")\n",
    "\tf.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57600, 28, 28, 3) train samples\n",
      "(38400, 28, 28, 3) test samples\n",
      "(57600,) train samples\n",
      "(38400,) test samples\n",
      "x_train shape: 57600\n",
      "y_train shape: 38400\n",
      "0 train samples\n",
      "0 test samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "57600/57600 [==============================] - 346s 6ms/step - loss: 1.6531 - acc: 0.5905\n"
     ]
    }
   ],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# x_train=np.load('../q1_data/x_train.npy')\n",
    "# y_train=np.load('../q1_data/y_train.npy')\n",
    "# y_train_length = np.load('../q1_data/y_train_length.npy')\n",
    "# y_train_width=np.load('../q1_data/y_train_width.npy')\n",
    "# y_train_angle = np.load('../q1_data/y_train_angle.npy')\n",
    "# y_train_color = np.load('../q1_data/y_train_color.npy')\n",
    "# x_test=np.load('../q1_data/x_test.npy')\n",
    "# y_test=np.load('../q1_data/y_test.npy')\n",
    "# y_test_length = np.load('../q1_data/y_test_length.npy')\n",
    "# y_test_width = np.load('../q1_data/y_test_width.npy')\n",
    "# y_test_angle = np.load('../q1_data/y_test_angle.npy')\n",
    "# y_test_color = np.load('../q1_data/y_test_color.npy')\n",
    "# print(x_test.size)\n",
    "\n",
    "# batch_size = 128\n",
    "# num_classes = 96\n",
    "# epochs = 1\t\n",
    "# train_example=int(x_train.shape[0]/100)\n",
    "# test_example=int(x_test.shape[0]/100)\n",
    "\n",
    "# # input image dimensions\n",
    "# image_rows, image_columns = 28, 28\n",
    "# image_size = 28*28*3\n",
    "\n",
    "\n",
    "# y_test1=y_test[0:test_example]\n",
    "\n",
    "# x_train_size = x_train.shape[0]\n",
    "# x_test_size = x_test.shape[0]\n",
    "\n",
    "\n",
    "# print(x_train.shape, 'train samples')\n",
    "# print(x_test.shape, 'test samples')\n",
    "# print(y_train.shape, 'train samples')\n",
    "# print(y_test.shape, 'test samples')\n",
    "\n",
    "# print(len(y_train_angle))\n",
    "\n",
    "\n",
    "# # convert class labels to hot encoding vectors\n",
    "# y_train_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_train_length_hot = keras.utils.to_categorical(y_train_length, 2)\n",
    "# y_train_width_hot = keras.utils.to_categorical(y_train_width, 2)\n",
    "# y_train_angle_hot = keras.utils.to_categorical(y_train_angle, 12)\n",
    "# y_train_color_hot = keras.utils.to_categorical(y_train_color, 2)\n",
    "\n",
    "# y_test_hot = keras.utils.to_categorical(y_test, num_classes)\n",
    "# y_test_length_hot = keras.utils.to_categorical(y_test_length, 2)\n",
    "# y_test_width_hot = keras.utils.to_categorical(y_test_width, 2)\n",
    "# y_test_angle_hot = keras.utils.to_categorical(y_test_angle, 12)\n",
    "# y_test_color_hot = keras.utils.to_categorical(y_test_color, 2)\n",
    "\n",
    "\n",
    "\n",
    "# # network structure\n",
    "# input = Input(shape=(28,28,3))\n",
    "\n",
    "# h1 = Conv2D(32, kernel_size=(7, 7), strides=(1, 1))(input)\n",
    "# h1 = ReLU()(h1)\n",
    "# h1 = BatchNormalization()(h1)\n",
    "# h1 = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(h1)\n",
    "\n",
    "\n",
    "\n",
    "# thread_1 = Flatten()(h1)\n",
    "# thread_1 = Dense(1024)(thread_1)\n",
    "# thread_1 = ReLU()(thread_1)\n",
    "# width_output = Dense(2, activation='sigmoid')(thread_1)\n",
    "\n",
    "# thread_2 = Flatten()(h1)\n",
    "# thread_2 = Dense(1024)(thread_2)\n",
    "# thread_2\t = ReLU()(thread_2)\n",
    "# color_output = Dense(2, activation='sigmoid')(thread_2)\n",
    "\n",
    "# thread_3 = Flatten()(h1)\n",
    "# thread_3 = Dense(1024)(thread_3)\n",
    "# thread_3 = ReLU()(thread_3)\n",
    "# length_output = Dense(2, activation='sigmoid')(thread_3)\n",
    "\n",
    "# thread_4 = Flatten()(h1)\n",
    "# thread_4 = Dense(1024)(thread_4)\n",
    "# thread_4 = ReLU()(thread_4)\n",
    "# angle_output = Dense(12, activation='softmax')(thread_4)\n",
    "\n",
    "# layer_width = 'dense_2'\n",
    "# layer_color = 'dense_4'\n",
    "# layer_length = 'dense_6'\n",
    "# layer_angle = 'dense_8'\n",
    "\n",
    "# losses = {\n",
    "# \tlayer_width: 'binary_crossentropy',\n",
    "# \tlayer_color: 'binary_crossentropy',\n",
    "# \tlayer_length: 'binary_crossentropy'\n",
    "# \t,\n",
    "# \tlayer_angle: 'categorical_crossentropy'\n",
    "# }\n",
    "# metrics = {\n",
    "# \tlayer_width: 'accuracy',\n",
    "# \tlayer_color: 'accuracy',\n",
    "# \tlayer_length: 'accuracy'\n",
    "# \t,\n",
    "# \tlayer_angle: 'accuracy'\n",
    "# }\n",
    "# lossWeights = {layer_width: 0.1, layer_color: 0.1, layer_length: 0.1, layer_angle: 0.6}\n",
    "\n",
    "# outputs=[width_output,color_output,length_output,angle_output]\n",
    "# X_test=x_test[0:test_example]\n",
    "# Y_train=[y_train_width_hot[0:train_example],y_train_color_hot[0:train_example],y_train_length_hot[0:train_example],y_train_angle_hot[0:train_example]]\n",
    "# Y_test=[y_test_width_hot[0:test_example],y_test_color_hot[0:test_example],y_test_length_hot[0:test_example],y_test_angle_hot[0:test_example]]\n",
    "\n",
    "# Y_test1={\n",
    "# \tlayer_width: y_test_width_hot[0:test_example],\n",
    "# \tlayer_color: y_test_color_hot[0:test_example],\n",
    "# \tlayer_length: y_test_length_hot[0:test_example]\n",
    "# \t,\n",
    "# \tlayer_angle: y_test_angle_hot[0:test_example]\n",
    "# }\n",
    "\n",
    "# model = Model(inputs=input, outputs=outputs)\n",
    "# model.summary()\n",
    "# print(len(model.layers))\n",
    "# model.compile(loss=losses,loss_weights=lossWeights,optimizer=keras.optimizers.Adam(),metrics=metrics)\n",
    "# history = model.fit(x_train[0:train_example], y=Y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test,Y_test1),callbacks=[tbCallBack])\n",
    "\n",
    "x_train=np.load('../q1_data/x_train.npy')\n",
    "y_train=np.load('../q1_data/y_train.npy')\n",
    "x_test=np.load('../q1_data/x_test.npy')\n",
    "y_test=np.load('../q1_data/y_test.npy')\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 96\n",
    "epochs = 1\n",
    "train_example=int(x_train.shape[0]/1)\n",
    "test_example=int(x_test.shape[0]/1)\n",
    "\n",
    "# input image dimensions\n",
    "# img_rows, img_cols = 28, 28\n",
    "image_rows, image_columns = 28, 28\n",
    "\n",
    "\n",
    "y_test1=y_test[0:test_example]\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train_size = x_train.shape[0]\n",
    "x_test_size = x_test.shape[0]\n",
    "\n",
    "# x_train = x_train.reshape(x_train_size,28*28*3)\n",
    "# x_test = x_test.reshape(x_test_size,28*28*3)\n",
    "\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "\n",
    "print(y_train.shape, 'train samples')\n",
    "print(y_test.shape, 'test samples')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices (hot encoding)\n",
    "y_train_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('x_train shape:', x_train_size)\n",
    "print('y_train shape:', x_test_size)\n",
    "# print('x_test shape:', x_test.shape)\n",
    "# print('y_test_hot shape:', y_test.shape)\n",
    "\n",
    "print(y_train[0], 'train samples')\n",
    "print(y_test[0], 'test samples')\n",
    "\n",
    "# Create a model with the above specified network architecture. Use the Adam optimizer\n",
    "# with categorical crossentropy loss. Once the model is trained test it using the test data.\n",
    "\n",
    "model = Sequential()\n",
    "# 1. 7x7 Convolutional Layer with 32 filters and stride of 1.\n",
    "model.add(Conv2D(32, kernel_size=(7, 7), strides=(1, 1), input_shape=(28,28,3)))\n",
    "# 2. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# 3. Batch Normalization Layer\n",
    "model.add(BatchNormalization())\n",
    "# 4. 2x2 Max Pooling layer with a stride of 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "# 5. fully connected layer with 1024 output units.\n",
    "model.add(Dense(1024))\n",
    "# 6. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# final layer with output neurons same as no. of classes\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# [,keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()]\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train[0:train_example], y_train_hot[0:train_example],\n",
    "\t\t  batch_size=batch_size,\n",
    "\t\t  epochs=epochs,\n",
    "\t\t  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 32)        1600      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 22, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 11, 11, 1024)      33792     \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 123904)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1239050   \n",
      "=================================================================\n",
      "Total params: 1,274,570\n",
      "Trainable params: 1,274,506\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 268s 4ms/step - loss: 0.3654 - acc: 0.9522\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "epochs=1\n",
    "batch_size=128\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train=x_train.reshape((60000,28,28,1))\n",
    "x_test=x_test.reshape((10000,28,28,1))\n",
    "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "print(x_train.shape)\n",
    "model = Sequential()\n",
    "# 1. 7x7 Convolutional Layer with 32 filters and stride of 1.\n",
    "model.add(Conv2D(32, kernel_size=(7, 7), strides=(1, 1), input_shape=(28,28,1)))\n",
    "# 2. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# 3. Batch Normalization Layer\n",
    "model.add(BatchNormalization())\n",
    "# 4. 2x2 Max Pooling layer with a stride of 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "# 5. fully connected layer with 1024 output units.\n",
    "model.add(Dense(1024))\n",
    "# 6. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# final layer with output neurons same as no. of classes\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# [,keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()]\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f286279810a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimg_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "for j in range(6):\n",
    "    img_tensor = x_test[random.randint(0,10000)]\n",
    "    img_new=img_tensor.reshape((28,28))\n",
    "    plt.imshow(img_new,'gray')\n",
    "    plt.show()\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "    print(img_tensor.shape)\n",
    "\n",
    "    layer_outputs = [layer.output for layer in model.layers[0:4]]\n",
    "    print(layer_outputs)\n",
    "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "    activation_model.summary()\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "\n",
    "    print((activations[0].shape[-1]))\n",
    "    print((activations[0].shape[1]))\n",
    "    print(len(activations[0][0]))\n",
    "    print(len(activations[0][0][0]))\n",
    "    print(len(activations[0][0][0][0]))\n",
    "    first_layer_activation = activations[0]\n",
    "    print(first_layer_activation.shape)\t\t\n",
    "    plt.imshow(first_layer_activation[0, :, :, 4], cmap='viridis')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    layer_names = []\n",
    "    for layer in model.layers[0:4]:\n",
    "        layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
    "        print(layer.name)\n",
    "    images_per_row = 16\n",
    "\n",
    "    layerno=1\n",
    "    for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
    "        n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
    "        size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
    "        n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,\n",
    "                                                 :, :,\n",
    "                                                 col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size, # Displays the grid\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "        plt.savefig(\"Section1/MNIST/image\"+str(j+1)+\"/layer\"+str(layerno))\n",
    "        layerno+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
