{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, ReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import random\n",
    "from keras import models\n",
    "import keras.backend as K\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras import backend as K\n",
    "import h5py\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57600, 28, 28, 3) train samples\n",
      "(38400, 28, 28, 3) test samples\n",
      "(57600,) train samples\n",
      "(38400,) test samples\n",
      "x_train shape: 57600\n",
      "y_train shape: 38400\n",
      "0 train samples\n",
      "0 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train=np.load('../q1_data/x_train.npy')\n",
    "y_train=np.load('../q1_data/y_train.npy')\n",
    "x_test=np.load('../q1_data/x_test.npy')\n",
    "y_test=np.load('../q1_data/y_test.npy')\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 96\n",
    "epochs = 5\n",
    "train_example=int(x_train.shape[0]/1)\n",
    "test_example=int(x_test.shape[0]/1)\n",
    "\n",
    "# input image dimensions\n",
    "# img_rows, img_cols = 28, 28\n",
    "image_rows, image_columns = 28, 28\n",
    "\n",
    "\n",
    "y_test1=y_test[0:test_example]\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train_size = x_train.shape[0]\n",
    "x_test_size = x_test.shape[0]\n",
    "\n",
    "# x_train = x_train.reshape(x_train_size,28*28*3)\n",
    "# x_test = x_test.reshape(x_test_size,28*28*3)\n",
    "\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "\n",
    "print(y_train.shape, 'train samples')\n",
    "print(y_test.shape, 'test samples')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices (hot encoding)\n",
    "y_train_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('x_train shape:', x_train_size)\n",
    "print('y_train shape:', x_test_size)\n",
    "# print('x_test shape:', x_test.shape)\n",
    "# print('y_test_hot shape:', y_test.shape)\n",
    "\n",
    "print(y_train[0], 'train samples')\n",
    "print(y_test[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "57600/57600 [==============================] - 220s 4ms/step - loss: 1.6408 - acc: 0.6379\n"
     ]
    }
   ],
   "source": [
    "# Create a model with the above specified network architecture. Use the Adam optimizer\n",
    "# with categorical crossentropy loss. Once the model is trained test it using the test data.\n",
    "\n",
    "model = Sequential()\n",
    "# 1. 7x7 Convolutional Layer with 32 filters and stride of 1.\n",
    "model.add(Conv2D(32, kernel_size=(7, 7), strides=(1, 1), input_shape=(28,28,3),padding=\"same\"))\n",
    "# 2. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# 3. Batch Normalization Layer\n",
    "model.add(BatchNormalization())\n",
    "# 4. 2x2 Max Pooling layer with a stride of 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "# 5. fully connected layer with 1024 output units.\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024))\n",
    "# # 6. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# # final layer with output neurons same as no. of classes\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# [,keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()]\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train[0:train_example], y_train_hot[0:train_example],\n",
    "\t\t  batch_size=batch_size,\n",
    "\t\t  epochs=1,\n",
    "\t\t  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        4736      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              6423552   \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 96)                98400     \n",
      "=================================================================\n",
      "Total params: 6,526,816\n",
      "Trainable params: 6,526,752\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 32)        1600      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 22, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11, 11, 1024)      33792     \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 11, 11, 1024)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 123904)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1239050   \n",
      "=================================================================\n",
      "Total params: 1,274,570\n",
      "Trainable params: 1,274,506\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.4919 - acc: 0.9469\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "epochs=1\n",
    "batch_size=128\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train=x_train.reshape((60000,28,28,1))\n",
    "x_test=x_test.reshape((10000,28,28,1))\n",
    "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "print(x_train.shape)\n",
    "model = Sequential()\n",
    "# 1. 7x7 Convolutional Layer with 32 filters and stride of 1.\n",
    "model.add(Conv2D(32, kernel_size=(7, 7), strides=(1, 1), input_shape=(28,28,1)))\n",
    "# 2. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# 3. Batch Normalization Layer\n",
    "model.add(BatchNormalization())\n",
    "# 4. 2x2 Max Pooling layer with a stride of 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "# 5. fully connected layer with 1024 output units.\n",
    "model.add(Dense(1024))\n",
    "# 6. ReLU Activation Layer.\n",
    "model.add(ReLU())\n",
    "# final layer with output neurons same as no. of classes\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# [,keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()]\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57600, 28, 28, 3) train samples\n",
      "(38400, 28, 28, 3) test samples\n",
      "(57600,) train samples\n",
      "(38400,) test samples\n",
      "57600\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 22, 22, 32)   4736        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 22, 22, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 22, 22, 32)   128         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3872)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3872)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3872)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 3872)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         3965952     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         3965952     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         3965952     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         3965952     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 1024)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            2050        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            2050        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 12)           12300       re_lu_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,887,122\n",
      "Trainable params: 15,887,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 57600 samples, validate on 38400 samples\n",
      "Epoch 1/1\n",
      "57600/57600 [==============================] - 318s 6ms/step - loss: 0.3798 - dense_2_loss: 0.0512 - dense_4_loss: 0.0165 - dense_6_loss: 0.1205 - dense_8_loss: 0.6017 - dense_2_acc: 0.9841 - dense_4_acc: 0.9937 - dense_6_acc: 0.9664 - dense_8_acc: 0.8354 - val_loss: 0.0680 - val_dense_2_loss: 0.0097 - val_dense_4_loss: 0.0043 - val_dense_6_loss: 0.0128 - val_dense_8_loss: 0.1088 - val_dense_2_acc: 0.9965 - val_dense_4_acc: 0.9985 - val_dense_6_acc: 0.9955 - val_dense_8_acc: 0.9623\n"
     ]
    }
   ],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "x_train=np.load('../q1_data/x_train.npy')\n",
    "y_train=np.load('../q1_data/y_train.npy')\n",
    "y_train_length = np.load('../q1_data/y_train_length.npy')\n",
    "y_train_width=np.load('../q1_data/y_train_width.npy')\n",
    "y_train_angle = np.load('../q1_data/y_train_angle.npy')\n",
    "y_train_color = np.load('../q1_data/y_train_color.npy')\n",
    "x_test=np.load('../q1_data/x_test.npy')\n",
    "y_test=np.load('../q1_data/y_test.npy')\n",
    "y_test_length = np.load('../q1_data/y_test_length.npy')\n",
    "y_test_width = np.load('../q1_data/y_test_width.npy')\n",
    "y_test_angle = np.load('../q1_data/y_test_angle.npy')\n",
    "y_test_color = np.load('../q1_data/y_test_color.npy')\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 96\n",
    "epochs = 5\n",
    "train_example=int(x_train.shape[0]/1)\n",
    "test_example=int(x_test.shape[0]/1)\n",
    "\n",
    "# input image dimensions\n",
    "image_rows, image_columns = 28, 28\n",
    "image_size = 28*28*3\n",
    "\n",
    "\n",
    "y_test1=y_test[0:test_example]\n",
    "\n",
    "x_train_size = x_train.shape[0]\n",
    "x_test_size = x_test.shape[0]\n",
    "\n",
    "\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "print(y_train.shape, 'train samples')\n",
    "print(y_test.shape, 'test samples')\n",
    "\n",
    "print(len(y_train_angle))\n",
    "\n",
    "\n",
    "# convert class labels to hot encoding vectors\n",
    "y_train_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_train_length_hot = keras.utils.to_categorical(y_train_length, 2)\n",
    "y_train_width_hot = keras.utils.to_categorical(y_train_width, 2)\n",
    "y_train_angle_hot = keras.utils.to_categorical(y_train_angle, 12)\n",
    "y_train_color_hot = keras.utils.to_categorical(y_train_color, 2)\n",
    "\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_test_length_hot = keras.utils.to_categorical(y_test_length, 2)\n",
    "y_test_width_hot = keras.utils.to_categorical(y_test_width, 2)\n",
    "y_test_angle_hot = keras.utils.to_categorical(y_test_angle, 12)\n",
    "y_test_color_hot = keras.utils.to_categorical(y_test_color, 2)\n",
    "\n",
    "\n",
    "\n",
    "# network structure\n",
    "input = Input(shape=(28,28,3))\n",
    "\n",
    "h1 = Conv2D(32, kernel_size=(7, 7), strides=(1, 1))(input)\n",
    "h1 = ReLU()(h1)\n",
    "h1 = BatchNormalization()(h1)\n",
    "h1 = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(h1)\n",
    "\n",
    "\n",
    "\n",
    "thread_1 = Flatten()(h1)\n",
    "thread_1 = Dense(1024)(thread_1)\n",
    "thread_1 = ReLU()(thread_1)\n",
    "width_output = Dense(2, activation='sigmoid')(thread_1)\n",
    "\n",
    "thread_2 = Flatten()(h1)\n",
    "thread_2 = Dense(1024)(thread_2)\n",
    "thread_2\t = ReLU()(thread_2)\n",
    "color_output = Dense(2, activation='sigmoid')(thread_2)\n",
    "\n",
    "thread_3 = Flatten()(h1)\n",
    "thread_3 = Dense(1024)(thread_3)\n",
    "thread_3 = ReLU()(thread_3)\n",
    "length_output = Dense(2, activation='sigmoid')(thread_3)\n",
    "\n",
    "thread_4 = Flatten()(h1)\n",
    "thread_4 = Dense(1024)(thread_4)\n",
    "thread_4 = ReLU()(thread_4)\n",
    "angle_output = Dense(12, activation='softmax')(thread_4)\n",
    "\n",
    "layer_width = 'dense_2'\n",
    "layer_color = 'dense_4'\n",
    "layer_length = 'dense_6'\n",
    "layer_angle = 'dense_8'\n",
    "\n",
    "losses = {\n",
    "\tlayer_width: 'binary_crossentropy',\n",
    "\tlayer_color: 'binary_crossentropy',\n",
    "\tlayer_length: 'binary_crossentropy'\n",
    "\t,\n",
    "\tlayer_angle: 'categorical_crossentropy'\n",
    "}\n",
    "metrics = {\n",
    "\tlayer_width: 'accuracy',\n",
    "\tlayer_color: 'accuracy',\n",
    "\tlayer_length: 'accuracy'\n",
    "\t,\n",
    "\tlayer_angle: 'accuracy'\n",
    "}\n",
    "lossWeights = {layer_width: 0.1, layer_color: 0.1, layer_length: 0.1, layer_angle: 0.6}\n",
    "\n",
    "outputs=[width_output,color_output,length_output,angle_output]\n",
    "X_test=x_test[0:test_example]\n",
    "Y_train=[y_train_width_hot[0:train_example],y_train_color_hot[0:train_example],y_train_length_hot[0:train_example],y_train_angle_hot[0:train_example]]\n",
    "Y_test=[y_test_width_hot[0:test_example],y_test_color_hot[0:test_example],y_test_length_hot[0:test_example],y_test_angle_hot[0:test_example]]\n",
    "\n",
    "Y_test1={\n",
    "\tlayer_width: y_test_width_hot[0:test_example],\n",
    "\tlayer_color: y_test_color_hot[0:test_example],\n",
    "\tlayer_length: y_test_length_hot[0:test_example]\n",
    "\t,\n",
    "\tlayer_angle: y_test_angle_hot[0:test_example]\n",
    "}\n",
    "\n",
    "model = Model(inputs=input, outputs=outputs)\n",
    "model.summary()\n",
    "model.compile(loss=losses,loss_weights=lossWeights,optimizer=keras.optimizers.Adam(),metrics=metrics)\n",
    "history = model.fit(x_train[0:train_example], y=Y_train,batch_size=batch_size,epochs=1,verbose=1,validation_data=(X_test,Y_test1),callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "(28, 28, 3)\n",
      "(1, 28, 28, 3)\n",
      "[<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_8/Softmax:0' shape=(?, 12) dtype=float32>]\n",
      "(11, 11)\n",
      "(28, 28, 3)\n",
      "(28, 28, 3)\n",
      "(1, 28, 28, 3)\n",
      "[<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_8/Softmax:0' shape=(?, 12) dtype=float32>]\n",
      "(11, 11)\n",
      "(28, 28, 3)\n",
      "(28, 28, 3)\n",
      "(1, 28, 28, 3)\n",
      "[<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_8/Softmax:0' shape=(?, 12) dtype=float32>]\n",
      "(11, 11)\n",
      "(28, 28, 3)\n",
      "(28, 28, 3)\n",
      "(1, 28, 28, 3)\n",
      "[<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_8/Softmax:0' shape=(?, 12) dtype=float32>]\n",
      "(11, 11)\n",
      "(28, 28, 3)\n",
      "(28, 28, 3)\n",
      "(1, 28, 28, 3)\n",
      "[<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_8/Softmax:0' shape=(?, 12) dtype=float32>]\n",
      "(11, 11)\n",
      "(28, 28, 3)\n",
      "(28, 28, 3)\n",
      "(1, 28, 28, 3)\n",
      "[<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Sigmoid:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_8/Softmax:0' shape=(?, 12) dtype=float32>]\n",
      "(11, 11)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4600bd3c8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j in range(6):\n",
    "    img = x_test[random.randint(0,10000)]\n",
    "    print(img.shape)\n",
    "#     img=img.reshape((28,28))\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.savefig(\"Section2/Image\"+str(j+1)+\"/image\")\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    print(x.shape)\n",
    "\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    #print (\"Predicted: \", decode_predictions(preds, top=3)[0])\n",
    "\n",
    "    #985 is the class index for class 'Daisy' in Imagenet dataset on which my model is pre-trained\n",
    "    print(model.output)\n",
    "    flower_output = model.output[1]\n",
    "    last_conv_layer = model.get_layer('max_pooling2d_1')\n",
    "\n",
    "    grads = K.gradients(flower_output, last_conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "    #2048 is the number of filters/channels in 'mixed10' layer\n",
    "    for i in range(32):\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    print(heatmap.shape)\n",
    "#     heatmap=heatmap.reshape((11,11))\n",
    "    plt.imshow(heatmap)\n",
    "    plt.savefig(\"Section2/Image\"+str(j+1)+\"/HeatmapForClass1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
